{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vzOavFVJteMB",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Композиции классификаторов (градиентный бустинг)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UCn8xDPhteMB",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#!pip install catboost\n",
    "#!pip install lightgbm\n",
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s3qWY0M5LA6r",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K2_VhyWeteMB",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import base\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold, RepeatedKFold\n",
    "from sklearn.datasets import make_classification, make_regression\n",
    "\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vqhbF2bhteMB",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ComBoost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "gd9uoXmriG-D",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Рассмотрим следующее ансамблирование ответов:\n",
    "$$\n",
    "b(x) = \\frac{1}{T}\\sum_{t=1}^{T} b_t(x)\n",
    "$$\n",
    "\n",
    "Рассмотрим отступ объектов:\n",
    "$$\n",
    "M(x) = \\Gamma_{y_t}\\bigr(x\\bigr) - \\max_{y \\neq y_t} \\Gamma_y\\bigr(x\\bigr)\n",
    "$$\n",
    "\n",
    "Идея в том, что каждый $b_t$ компенсирует ошибки ансамбля, состоящего из всех предыдущих моделей:\n",
    "$$\n",
    "Q\\bigr(b_t, U_t\\bigr) = \\sum_{x \\in U_t}\\left[M(x) < 0\\right] \\to \\min_{b_t},\n",
    "$$\n",
    "$$\n",
    "U_t = \\left\\{x| M_l < M_{t-1}(x) < M_g\\right\\}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "beirFGPXteMB",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "class ComBoost(object):\n",
    "    def __init__(self, base_estimator=None, n_estimators=10):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.base_estimator = DecisionTreeClassifier(max_depth=1)\n",
    "        if base_estimator:\n",
    "            self.base_estimator = base_estimator\n",
    "        self.b = [base.clone(self.base_estimator) for _ in range(self.n_estimators)]\n",
    "        \n",
    "    def get_params(self, deep=True):\n",
    "        return {'n_estimators': self.n_estimators, \n",
    "                'base_estimator': self.base_estimator}\n",
    "\n",
    "    @staticmethod\n",
    "    def fix_predict_proba(pred, b, b0):\n",
    "        new_pred = np.zeros((len(pred), len(b0.classes_)))\n",
    "        for i, cl in enumerate(b.classes_):\n",
    "            new_pred[:, cl] = pred[:, i]\n",
    "        return new_pred\n",
    "        \n",
    "    def fit(self, X, Y, l0=0, l1=100, l2=None, dl=100):\n",
    "        def margin(pr, y):\n",
    "            cop = pr.copy()\n",
    "            cop[y] = -1\n",
    "            return pr[y] - cop.max()\n",
    "        \n",
    "        if l2 is None:\n",
    "            l2 = len(X)\n",
    "        \n",
    "        for t, b in enumerate(self.b):\n",
    "            if t == 0:\n",
    "                b.fit(X, Y)\n",
    "                pred = b.predict_proba(X)\n",
    "                M = np.array([margin(pred[i], Y[i]) for i in range(len(Y))])\n",
    "            else:\n",
    "                indexes = sorted(np.arange(0, len(X)), key = lambda i: M[i])\n",
    "                X_new = X[indexes]\n",
    "                Y_new = Y[indexes]\n",
    "                dict_of_param = []\n",
    "                for k in range(l1, l2, dl):\n",
    "                    new_item = {'l0': l0, 'k': k}\n",
    "                    \n",
    "                    local_b = base.clone(self.base_estimator)\n",
    "                    local_b.fit(X_new[l0:k], Y_new[l0:k])\n",
    "                    \n",
    "                    pred = self.fix_predict_proba(local_b.predict_proba(X), local_b, self.b[0])\n",
    "                    M_new = np.array([margin(pred[i], Y[i]) for i in range(len(Y))])\n",
    "                    \n",
    "                    new_item['Q'] = (M + M_new < 0).sum()\n",
    "                    dict_of_param.append(new_item)\n",
    "                    \n",
    "                element = sorted(dict_of_param, key=lambda x: x['Q'])[0]\n",
    "                b.fit(X_new[element['l0']:element['k']], \n",
    "                      Y_new[element['l0']:element['k']])\n",
    "                \n",
    "                pred = self.fix_predict_proba(b.predict_proba(X), local_b, self.b[0])\n",
    "                M = M + np.array([margin(pred[i], Y[i]) for i in range(len(Y))])\n",
    "                \n",
    "                    \n",
    "    def predict(self, X):\n",
    "        probas = self.predict_proba(X)\n",
    "        return np.argmax(probas, axis=1)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return np.mean([self.fix_predict_proba(elem.predict_proba(X), elem, self.b[0]) for elem in self.b], axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zTd5BOnViG-D",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Пример использования\n",
    "\n",
    "Данный метод позволяет строить ансамли для произвольных базовых функций. Далее приводится пример для решающего дерева."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NmrGEYhliG-D",
    "outputId": "b5423bef-0498-4109-e12b-6ef52f44219a",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model = DecisionTreeClassifier(max_depth=2)\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "print('SCORE: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cT-L6N5OteMC",
    "outputId": "982a1f16-bf59-495a-b24b-d42020bcba18",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model = ComBoost(DecisionTreeClassifier(max_depth=2), n_estimators=100)\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "print('SCORE: %.2f (%.2f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Q9U6IpKqiG-E",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Выводы\n",
    "Получаем, что ансамблирование не ухудшает качества на кроссвалидации. В случае простых моделей (дерево с ограниченной глубиной), качество улучшается значительно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MmhySFdjteMC",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tunQC0X_iG-E",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Рассмотрим следующее ансамблирование ответов:\n",
    "$$\n",
    "b(x) = \\sum_{t=1}^{T} b_t(x)\n",
    "$$\n",
    "\n",
    "Рассмотрим среднеквадратичекое отклонение:\n",
    "$$\n",
    "L = \\sum_{i=1}^{l}\\left(b(x_i) - y_i\\right)^2\n",
    "$$\n",
    "\n",
    "Идея состоит в том, что каждая новая модель пытается аппроксимировать остатки которые оставили прошлые модели:\n",
    "$$\n",
    "L_t = \\sum_{i=1}^{l}\\left(b_t(x_i) - (y_i - \\sum_{j=1}^{t}b_j(x_i))\\right)^2 \\min_{b_t}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hLC8MVOuteMC",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class GradientBoostingRegression(object):\n",
    "    def __init__(self, base_estimator=None, n_estimators=10):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.base_estimator = DecisionTreeRegressor(max_depth=1)\n",
    "        if base_estimator:\n",
    "            self.base_estimator = base_estimator\n",
    "            \n",
    "        self.b = [base.clone(self.base_estimator) for _ in range(self.n_estimators)]\n",
    "        \n",
    "    def get_params(self, deep=True):\n",
    "        return {'n_estimators': self.n_estimators, \n",
    "                'base_estimator': self.base_estimator}\n",
    "        \n",
    "    def fit(self, X, Y):\n",
    "        residual = Y.copy()\n",
    "        for t, bt in enumerate(self.b):\n",
    "            bt.fit(X, residual)\n",
    "            residual = residual - bt.predict(X)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        return np.sum([elem.predict(X) for elem in self.b], axis=0)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Ov9tj-V0iG-E",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Пример использования\n",
    "\n",
    "Данный метод позволяет строить ансамли для произвольных базовых функций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(n_samples=1000, n_features=20, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dbmQUjEQiG-E",
    "outputId": "d20bd54e-dbdc-43a2-fd47-552f3ac0fedf",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model = DecisionTreeRegressor(max_depth=2)\n",
    "\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, cv=cv, n_jobs=-1, scoring=\"neg_mean_squared_error\")\n",
    "print('SCORE: %.2f (%.2f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GqEYhEkNteMC",
    "outputId": "6d47739a-99db-4829-cdb2-81404065899a",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model = GradientBoostingRegression(DecisionTreeRegressor(max_depth=2), n_estimators = 100)\n",
    "\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, cv=cv, n_jobs=-1, scoring=\"neg_mean_squared_error\")\n",
    "print('SCORE: %.2f (%.2f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nrFZTB31teMD",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## XGBoost"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "wCCwpr6xiG-E",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Пакет `xgboost` является один из библиотек для построения деревьев на основе градиентного бустинга. В основном все такие библиотеки работают только с решающими деревьями (ансамбли принято строить над деревьями), подробное описание модификации описано в [статье](https://www.kdd.org/kdd2016/papers/files/rfp0697-chenAemb.pdf).\n",
    "\n",
    "- Ускорение заключается в более оптимальном подборе порогов в каждой вершине дерева.\n",
    "- Модифицировали алгоритм для паралельного обучения деревьев (напомним, что классический бустинг не позволяет выполнять паралельную обработку).\n",
    "- Специальные инженерные трюки для сбалансированого использования кеша.\n",
    "\n",
    "Данный framework имеет следующие плюсы:\n",
    "- Хорошая документация.\n",
    "- Позволяет легко паралелить вычисления.\n",
    "- Легко использовать с `sklearn` и `numpy` (но с потерей производительности)\n",
    "\n",
    "Недостатки:\n",
    "- Отсутствует поддержка GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r4PnCcUkteMD",
    "outputId": "807a89c0-f477-448f-ac57-a5afe2074ba3",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=6)\n",
    "model = xgb.XGBClassifier(objective='binary:logistic', random_state=6)\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, cv=cv, n_jobs=-1)\n",
    "print('SCORE: %.2f (%.2f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vFLWA6VBteMD",
    "outputId": "634777ee-000b-44e1-fc88-207c710f00ef",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "X, y = make_regression(n_samples=1000, n_features=20, random_state=6)\n",
    "model = xgb.XGBRegressor(objective='reg:squarederror', random_state=6)\n",
    "\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, cv=cv, n_jobs=-1, scoring=\"neg_mean_squared_error\")\n",
    "print('SCORE: %.2f (%.2f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DH9UarKliG-F",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjHhQjheiG-F",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Пакет `lightgbm` представлен Microsoft как реализация градиентного бустинга над деревьями. Работа с подробным описаниям введений описана [тут](https://papers.nips.cc/paper/2017/file/6449f44a102fde848669bdd9eb6b76fa-Paper.pdf).\n",
    "\n",
    "Сам метод модифицирует метод XGboost с дополнительной процедурой ресемплинга объектов для ускорения построения деревьев.\n",
    "\n",
    "\n",
    "Данный фраймворк имеет следующие положительные моменты:\n",
    "- Хорошая документация.\n",
    "- Имеется поддержка GPU.\n",
    "- Имеет поддержку категориальных признаков на основе метода Фишера, который описан [тут](https://lightgbm.readthedocs.io/en/latest/Features.html#optimal-split-for-categorical-features).\n",
    "\n",
    "Недостатки:\n",
    "- Сложно использовать с `numpy` и `sklearn` так как требует специфичного формата данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xrcLqutziG-F",
    "outputId": "47518693-311f-418c-c954-1e0817430fac",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=6)\n",
    "\n",
    "train_data = lgb.Dataset(X, label=y)\n",
    "param = {'num_leaves': 31, \n",
    "         'objective': 'multiclass', \n",
    "         'num_class': 2, \n",
    "         'metric': ['multi_logloss']}\n",
    "\n",
    "num_round = 10\n",
    "bst = lgb.train(param, train_data, num_boost_round=10)\n",
    "\n",
    "(bst.predict(X).argmax(axis=-1) == y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2QK6_SiPteMD",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bqSCFb-iG-F",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Пакет `catboost` представлен Яндексом для построения ансамблей моделей на базе решающих деревьев. Подробное описание доступно в [работе](https://papers.nips.cc/paper/2018/file/14491b756b3a51daac41c24863285549-Paper.pdf).\n",
    "\n",
    "- Основной идеей и посылом для создания CatBoost была разработка метода работы с категориальными признаками (отсюда и названия).\n",
    "- В классическом машинном обучении принято категориальные признаки кодировать One-Hot векторами. В работе предлагался метод, который выделяет кластеры внутри категориального признака на основе предлагаемых в работе статистик.\n",
    "\n",
    "Данный framework имеет следующие плюсы:\n",
    "- Хорошая документация.\n",
    "- Позволяет легко паралелить вычисления на GPU.\n",
    "- Легко использовать с `sklearn` и `numpy` (но с потерей производительности).\n",
    "- Поддержка категориальных признаков (причем продвинутая, в отличии от простых методов Фишера).\n",
    "\n",
    "Недостатки:\n",
    "- Во многих задачах показывает себя хуже чем XGboost и LightGBM.\n",
    "- В статье показано, что данный метод работает лучше чем XGboost и LightGBM, но в реальных кейсах это не так..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8H7GxrtHteMD",
    "outputId": "54dc17f9-18dc-425b-f215-dc63f9e92f03",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=6)\n",
    "\n",
    "model = CatBoostClassifier(iterations=2,\n",
    "                           depth=2,\n",
    "                           learning_rate=1,\n",
    "                           loss_function='Logloss',\n",
    "                           verbose=True, task_type='CPU')\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, cv=cv, n_jobs=-1)\n",
    "print('SCORE: %.2f (%.2f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HcYKogs2tgxE",
    "outputId": "18a17456-9fa3-4480-de76-28348bbb356f",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=6)\n",
    "\n",
    "model = CatBoostClassifier(iterations=2,\n",
    "                           depth=2,\n",
    "                           learning_rate=1,\n",
    "                           loss_function='Logloss',\n",
    "                           verbose=True) #, task_type='GPU')\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(model, X, y, cv=cv, n_jobs=-1)\n",
    "print('SCORE: %.2f (%.2f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Slideshow",
  "colab": {
   "name": "main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
