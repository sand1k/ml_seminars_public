{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "vzOavFVJteMB",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Байесовская теория классификации"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "s3qWY0M5LA6r",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K2_VhyWeteMB",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import KFold, ParameterGrid\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UCn8xDPhteMB",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Принцип максимума правдоподобия\n",
    "\n",
    "Если $P\\bigr(y\\bigr)$ равномерная случайная величина, то\n",
    "$$\n",
    "a\\bigr(x\\bigr) = \\arg\\max_{y\\in Y} p\\bigr(x|y\\bigr)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "p_x_1 = stats.multivariate_normal([-1, -1], np.eye(2))\n",
    "p_x_2 = stats.multivariate_normal([1, 1], 1.5*np.eye(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def plot():\n",
    "    x = np.linspace(-3, 3, 300)\n",
    "    y = np.linspace(-3, 3, 300)\n",
    "    xs, ys = np.meshgrid(x, y)\n",
    "    scores = [np.zeros_like(xs), np.zeros_like(xs)]\n",
    "    for i in range(len(xs)):\n",
    "        for j in range(len(xs[i])):\n",
    "            scores[0][i][j] = p_x_1.pdf([xs[i][j],ys[i][j]])\n",
    "            scores[1][i][j] = p_x_2.pdf([xs[i][j],ys[i][j]])\n",
    "\n",
    "    ax = plt.figure(figsize=(14.0, 6.0)).gca(projection='3d')\n",
    "    alpha=0.7\n",
    "    ax.plot_surface(xs, ys, \n",
    "                    np.where(scores[1] <= scores[0], scores[1], np.nan),\n",
    "                    linewidth=0, color='blue', alpha=alpha)\n",
    "    ax.plot_surface(xs, ys, \n",
    "                    np.where(scores[0] <= scores[1], scores[0], np.nan), \n",
    "                    linewidth=0, color='red', alpha=alpha)\n",
    "    ax.plot_surface(xs, ys, \n",
    "                    np.where(scores[1] >= scores[0], scores[1], np.nan),\n",
    "                    linewidth=0, color='blue', alpha=alpha)\n",
    "    ax.plot_surface(xs, ys, \n",
    "                    np.where(scores[0] >= scores[1], scores[0], np.nan), \n",
    "                    linewidth=0, color='red', alpha=alpha)\n",
    "    ax.set_xlabel(r'x1', labelpad= 14), ax.set_ylabel(r'x2', labelpad=14)\n",
    "    ax.set_zlabel(r'p(x)'), ax.view_init(30, -120)\n",
    "    ax.view_init(30, -70)\n",
    "    plt.show()\n",
    "\n",
    "plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "В случае, если плотности $p(x|y)$ заданы, то задача классификации является решенной. Но вопрос как найти $p(x|y)$?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Одномерный случай"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Синтетические данные\n",
    "\n",
    "Рассмотрим две гаусианы с разными средними и дисперсиями. Сгенерим выборку, где каждая гаусиана описывает свой класс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "l = 10000\n",
    "p_x_1 = stats.norm(-1, 0.5)\n",
    "x_1 = np.sqrt(0.5)*np.random.randn(l)-1\n",
    "p_x_2 = stats.norm(1, 1.5)\n",
    "x_2 = np.sqrt(1.5)*np.random.randn(l)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(min(np.min(x_1), np.min(x_2)), \n",
    "                max(np.max(x_1), np.max(x_2)), 100)\n",
    "\n",
    "plt.plot(x_1, x_1*0, '.', color='blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(min(np.min(x_1), np.min(x_2)), \n",
    "                max(np.max(x_1), np.max(x_2)), 100)\n",
    "\n",
    "plt.plot(x_2, x_2*0, '.', color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(min(np.min(x_1), np.min(x_2)), max(np.max(x_1), np.max(x_2)), 100)\n",
    "plt.plot(x, p_x_1.pdf(x), color='blue', label='class 1')\n",
    "plt.plot(x, p_x_2.pdf(x), color='red', label='class 2')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Востановления плотности по эмпирическим данным\n",
    "Истинное распределение $p(x|y)$ не известно, востановим данную плотность $\\hat{p}(x|y, \\mathbf{X})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(x_1, bins=100)\n",
    "plt.hist(x_2, bins=100)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def p(x, D, h = 0.2):\n",
    "    D = np.array(D)\n",
    "    x = np.array(x)\n",
    "    l = len(D)\n",
    "    n = 1\n",
    "    if len(D.shape) == 2:\n",
    "        n = D.shape[1]\n",
    "        \n",
    "    D = D.reshape([-1, n])\n",
    "    x = x.reshape([-1, n])\n",
    "    return (1/(2*h))*(1/len(D))*(cdist(D, x, metric='minkowski', p=1) <= h).sum(axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(min(np.min(x_1), np.min(x_2)), max(np.max(x_1), np.max(x_2)), 100)\n",
    "\n",
    "plt.plot(x, p(x, x_1), color='blue', label='p(x|1)')\n",
    "plt.plot(x, p(x, x_2), color='red', label='p(x|2)')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(min(np.min(x_1), np.min(x_2)), \n",
    "                max(np.max(x_1), np.max(x_2)), 500)\n",
    "\n",
    "p1 = p(x, x_1)\n",
    "p2 = p(x, x_2)\n",
    "plt.plot(x, p1, color='blue', label='p(x|1)')\n",
    "plt.plot(x, p2, color='red', label='p(x|2)')\n",
    "\n",
    "idx = np.argwhere(np.diff(np.sign(p1 - p2))).flatten()\n",
    "plt.plot(x[idx], p1[idx], 'ko', label='threshold')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "x[idx]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### LOO для выбора ширины окна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def LOO(D, h):\n",
    "    D_list = D.tolist()\n",
    "    \n",
    "    for i in range(len(D_list)):\n",
    "        return -np.log(p([D_list[i]], D_list[:i] + D_list[i+1:], h)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "hs = np.linspace(1e-10, 2, 1000)\n",
    "scores_1 = [LOO(x_1, h) for h in hs]\n",
    "scores_2 = [LOO(x_2, h) for h in hs]\n",
    "\n",
    "plt.plot(hs, scores_1, color='blue', label='h for class 1')\n",
    "plt.plot(hs, scores_2, color='red', label='h for class 2')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "hs[np.argmin(scores_1)], hs[np.argmin(scores_2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(min(np.min(x_1), np.min(x_2)), \n",
    "                max(np.max(x_1), np.max(x_2)), 500)\n",
    "\n",
    "p1 = p(x, x_1, hs[np.argmin(scores_1)])\n",
    "p2 = p(x, x_2, hs[np.argmin(scores_2)])\n",
    "plt.plot(x, p1, color='blue', label='p(x|1)')\n",
    "plt.plot(x, p2, color='red', label='p(x|2)')\n",
    "\n",
    "idx = np.argwhere(np.diff(np.sign(p1 - p2))).flatten()\n",
    "plt.plot(x[idx], p1[idx], 'ko', label='threshold')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "x[idx]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Двумерный случай"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "l = 10000\n",
    "p_x_1 = stats.multivariate_normal([-1, -1], 0.5*np.eye(2))\n",
    "x_1 = np.sqrt(0.5)*np.random.randn(l, 2)+np.array([-1, -1])\n",
    "\n",
    "p_x_2 = stats.multivariate_normal([1, 1], 1.5*np.eye(2))\n",
    "x_2 = np.sqrt(1.5)*np.random.randn(l, 2)+np.array([1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def plot():\n",
    "    x = np.linspace(-3, 3, 300)\n",
    "    y = np.linspace(-3, 3, 300)\n",
    "    xs, ys = np.meshgrid(x, y)\n",
    "    scores = [np.zeros_like(xs), np.zeros_like(xs)]\n",
    "    for i in range(len(xs)):\n",
    "        for j in range(len(xs[i])):\n",
    "            scores[0][i][j] = p_x_1.pdf([xs[i][j],ys[i][j]])\n",
    "            scores[1][i][j] = p_x_2.pdf([xs[i][j],ys[i][j]])\n",
    "\n",
    "    ax = plt.figure(figsize=(14.0, 6.0)).gca(projection='3d')\n",
    "    alpha=0.7\n",
    "    ax.plot_surface(xs, ys, \n",
    "                    np.where(scores[1] <= scores[0], scores[1], np.nan),\n",
    "                    linewidth=0, color='blue', alpha=alpha)\n",
    "    ax.plot_surface(xs, ys, \n",
    "                    np.where(scores[0] <= scores[1], scores[0], np.nan), \n",
    "                    linewidth=0, color='red', alpha=alpha)\n",
    "    ax.plot_surface(xs, ys, \n",
    "                    np.where(scores[1] >= scores[0], scores[1], np.nan),\n",
    "                    linewidth=0, color='blue', alpha=alpha)\n",
    "    ax.plot_surface(xs, ys, \n",
    "                    np.where(scores[0] >= scores[1], scores[0], np.nan), \n",
    "                    linewidth=0, color='red', alpha=alpha)\n",
    "    ax.set_xlabel(r'x1', labelpad= 14), ax.set_ylabel(r'x2', labelpad=14)\n",
    "    ax.set_zlabel(r'p(x)'), ax.view_init(30, -120)\n",
    "    ax.view_init(30, -70)\n",
    "    plt.show()\n",
    "\n",
    "plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "hs = np.linspace(1e-10, 5, 20)\n",
    "scores_1 = [LOO(x_1, h) for h in hs]\n",
    "scores_2 = [LOO(x_2, h) for h in hs]\n",
    "\n",
    "plt.plot(hs, scores_1, color='blue', label='h for class 1')\n",
    "plt.plot(hs, scores_2, color='red', label='h for class 2')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "hs[np.argmin(scores_1)], hs[np.argmin(scores_2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def plot():\n",
    "    x = np.linspace(-3, 3, 300)\n",
    "    y = np.linspace(-3, 3, 300)\n",
    "    xs, ys = np.meshgrid(x, y)\n",
    "    scores = [np.zeros_like(xs), np.zeros_like(xs)]\n",
    "    for i in range(len(xs)):\n",
    "        line = np.array([[xs[i][j],ys[i][j]] for j in range(len(xs[i]))])\n",
    "        scores[0][i] = p(line, x_1, hs[np.argmin(scores_1)])\n",
    "        scores[1][i] = p(line, x_2, hs[np.argmin(scores_2)])\n",
    "\n",
    "    ax = plt.figure(figsize=(14.0, 6.0)).gca(projection='3d')\n",
    "    alpha=0.7\n",
    "    ax.plot_surface(xs, ys, \n",
    "                    np.where(scores[1] <= scores[0], scores[1], np.nan),\n",
    "                    linewidth=0, color='blue', alpha=alpha)\n",
    "    ax.plot_surface(xs, ys, \n",
    "                    np.where(scores[0] <= scores[1], scores[0], np.nan), \n",
    "                    linewidth=0, color='red', alpha=alpha)\n",
    "    ax.plot_surface(xs, ys, \n",
    "                    np.where(scores[1] >= scores[0], scores[1], np.nan),\n",
    "                    linewidth=0, color='blue', alpha=alpha)\n",
    "    ax.plot_surface(xs, ys, \n",
    "                    np.where(scores[0] >= scores[1], scores[0], np.nan), \n",
    "                    linewidth=0, color='red', alpha=alpha)\n",
    "    ax.set_xlabel(r'x1', labelpad= 14), ax.set_ylabel(r'x2', labelpad=14)\n",
    "    ax.set_zlabel(r'p(x)'), ax.view_init(30, -120)\n",
    "    ax.view_init(30, -70)\n",
    "    plt.show()\n",
    "\n",
    "plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Параметрическое востановление плотности"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Принцип максимума правдоподобия\n",
    "\n",
    "$$\n",
    "\\hat{\\theta} = \\arg\\max_{\\theta}L\\bigr(\\theta, \\mathbf{X}^{m}\\bigr) = \\sum_{i=1}^{m}\\ln p\\bigr(x_i| \\theta\\bigr)\n",
    "$$\n",
    "\n",
    "Пример для нормального распределения:\n",
    "$$\n",
    "\\mu = \\frac{1}{m}\\sum_{i=1}^{m}x_i.\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Нормировка данных"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Для реальных данных всегда нужно проводить предварительный анализ данных. В частности требуется выполнить нормировку данных. Нормировка данных позволяет повысить устойчивость модели при обучении."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "X, Y = make_classification(n_samples=150, n_features=2, \n",
    "                           n_informative=2, n_classes=2, \n",
    "                           n_redundant=0,\n",
    "                           n_clusters_per_class=1,\n",
    "                           random_state=40)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, \n",
    "                                                    test_size=50, \n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model = SVC(kernel='linear')\n",
    "_ = model.fit(X_train, Y_train)\n",
    "model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig, gs = plt.figure(figsize=(14,4)), gridspec.GridSpec(1, 3)\n",
    "\n",
    "ax = []\n",
    "for i in range(3):\n",
    "    ax.append(fig.add_subplot(gs[i]))\n",
    "\n",
    "\n",
    "plot_decision_regions(X_train, Y_train, model, ax=ax[0])\n",
    "plot_decision_regions(X_test, Y_test, model, ax=ax[1])\n",
    "plot_decision_regions(X_train[model.support_], Y_train[model.support_], model, ax=ax[2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "X, Y = make_classification(n_samples=150, n_features=2, \n",
    "                           n_informative=2, n_classes=2, \n",
    "                           n_redundant=0,\n",
    "                           n_clusters_per_class=1,\n",
    "                           random_state=40)\n",
    "\n",
    "X = (X + 1000*np.random.randn(1, 2)) * 1000*np.random.randn(1, 2)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=50, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model = SVC(kernel='linear')\n",
    "_ = model.fit(X_train, Y_train)\n",
    "model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig, gs = plt.figure(figsize=(14,4)), gridspec.GridSpec(1, 3)\n",
    "\n",
    "ax = []\n",
    "for i in range(3):\n",
    "    ax.append(fig.add_subplot(gs[i]))\n",
    "\n",
    "\n",
    "plot_decision_regions(X_train, Y_train, model, ax=ax[0])\n",
    "plot_decision_regions(X_test, Y_test, model, ax=ax[1])\n",
    "plot_decision_regions(X_train[model.support_], Y_train[model.support_], model, ax=ax[2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC(kernel='linear')\n",
    "_ = model.fit(X_train, Y_train)\n",
    "model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig, gs = plt.figure(figsize=(14,4)), gridspec.GridSpec(1, 3)\n",
    "\n",
    "ax = []\n",
    "for i in range(3):\n",
    "    ax.append(fig.add_subplot(gs[i]))\n",
    "\n",
    "\n",
    "plot_decision_regions(X_train, Y_train, model, ax=ax[0])\n",
    "plot_decision_regions(X_test, Y_test, model, ax=ax[1])\n",
    "plot_decision_regions(X_train[model.support_], Y_train[model.support_], model, ax=ax[2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Ирисы Фишера\n",
    "Выборка взята отсюда: https://archive.ics.uci.edu/ml/datasets/iris"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Загрузка выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/iris.csv', \n",
    "                      header=None, \n",
    "                      names=['длина чашелистика', 'ширина чашелистика', \n",
    "                             'длина лепестка', 'ширина лепестка', 'класс'])\n",
    "dataset.sample(5, random_state=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Начало работы с данными\n",
    "1. Определить множество объектов:\n",
    "    * Определить размер выборки\n",
    "    * Определить признаки, которыми описываются объекты\n",
    "2. Определить множество ответов\n",
    "3. Определить тип задачи машинного обучения\n",
    "6. ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Множество объектов\n",
    "В данной задачи множество объектов описывается $n=4$ признаками:\n",
    "1. Длина чашелистика\n",
    "2. Ширина чашелистика\n",
    "3. Длина лепестка\n",
    "4. Ширина лепестка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print('Размер выборки составляет l={} объектов.'.format(len(dataset)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Все признаки являются вещественными признаками. Формально объекты $\\mathbf{X}$ представляються в следующем виде:\n",
    "$$\\mathbf{X} \\in \\mathbb{R}^{l\\times n},$$\n",
    "где $l$ число объектов, а $n$ число признаков.\n",
    "\n",
    "Получаем, что $\\mathbf{X}$ это некоторая вещественная матрица размера $l\\times n$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Множество ответов\n",
    "В данной задаче множество ответов состоит из трех элементов:\n",
    "1. Iris-virginica\n",
    "2. Iris-versicolor\n",
    "3. Iris-setosa"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Задача машинного обучения\n",
    "В нашем случае, так как мощность множества $|\\mathbf{y}|=3 \\ll l=150$ получаем задачу классификации на $M=3$ класса."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Анализ данных\n",
    "Сначала проэктируем все объекты на двумерные плоскости, для упрощения анализа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(dataset, hue='класс', height=2)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Из рисунка видно, что класс синих точек (Iris-setosa) легко отделяется от двух других цветов. Оранжевые и зеленные точки отделяются не так просто в каждой из проэкций, но все равно можно провести прямую, которая отделит оранджевые точки от зеленых."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Построение модели\n",
    "### Преобразование данных\n",
    "Как было сказано ранее нам требуется решить задачу классификации на 3 класса. Но для наглядноси рассмотрим бинарную классификацию (классификацию на несколько классов рассмотрим в следующей лекции).\n",
    "\n",
    "Чтобы исходную задачу преобразовать в задачу бинарной классификации уберем из выборки все объекта класса Iris-setosa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "binary_dataset = dataset.drop(index=dataset.index[dataset['класс'] == 'Iris-setosa'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Классы закодируем целыми числами $-1$ и $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "binary_dataset.loc[dataset['класс'] == 'Iris-versicolor', dataset.columns == 'класс'] = -1\n",
    "binary_dataset.loc[dataset['класс'] == 'Iris-virginica', dataset.columns == 'класс'] = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Получаем задачу бинарной классификации."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Модель алгоритмов\n",
    "\n",
    "Модель алгоритмов $\\mathfrak{F}$ в машинном обучении это некоторое множество функций, которые действуют из множества объектов в множество ответов, в нашем случае:\n",
    "$$\\mathfrak{F} = \\{f| f: \\mathbb{R}^n \\to \\{-1, 1\\}, \\text{еще какие-то ограничения}\\},$$\n",
    "обычно $\\mathfrak{F}$ это некоторое параметрическое семество функций, тоесть разные функции $f$ отличаются друг от друга только каким-то параметром. Простым примером параметрическим семейством функций для задачи бинарной классификации является семейство линейный классификатор:\n",
    "$$\\mathfrak{F}_{bcl} = \\left\\{f\\bigr(\\theta, \\mathbf{x}\\bigr)=\\text{sign}\\bigr(\\theta^{\\mathsf{T}}\\mathbf{x}\\bigr)\\bigr| \\theta \\in \\mathbb{R}^{n} \\right\\}.$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Функция потерь\n",
    "\n",
    "Машиное обучение это всегда выбор функции из множества $\\mathfrak{F}$. Чтобы выбрать функцию, нужен некоторый критерий по которому она выбирается, то есть нужно упоррядочить все функции от худшей к лучшей. Для этого построем функционал $\\mathcal{L}$, который каждой функции $f \\in \\mathfrak{F}$ ставит в соответствии число из $\\mathbb{R}_+$. В машинном обучении обычно функционал качества водиться как некоторая ошибка на выборке. В общем виде функционал качества можно представить в следующем виде:\n",
    "$$\\mathcal{L}\\bigr(f, \\mathbf{X}, \\mathbf{y}\\bigr) = \\sum_{i=1}^l\\mathcal{q}\\bigr(f, \\mathbf{x}_i, y_i\\bigr),$$\n",
    "где $q$ некоторая функция ошибки на некотором объекте $\\mathbf{x}$. Функционал качества $\\mathcal{L}$ называется эмперическим риском."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Оптимизационная задача\n",
    "\n",
    "Далее нужно поставить задачу оптимизации для выбора $f \\in \\mathfrak{F}$. Здесь все просто, просто минимизируем эмперический риск:\n",
    "$$\\hat{f} = \\arg \\min_{f \\in \\mathfrak{F}} \\mathcal{L}\\bigr(f, \\mathbf{X}, \\mathbf{y}\\bigr).$$\n",
    "\n",
    "Важно! В результе функция $\\hat{f}$ зависит от выборки $\\left(\\mathbf{X}, \\mathbf{y}\\right)$, то есть для разных наборов данных оптимальная функция будет различная."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Вернемся к нашей задаче. В нашем случае функционал качества будет иметь следующий вид:\n",
    "$$\\mathcal{L}\\bigr(\\theta, \\mathbf{X}, \\mathbf{y}\\bigr) = \\sum_{i=1}^l\\bigr[f\\bigr(\\theta, \\mathbf{x}_i\\bigr) \\not= y_i\\bigr],$$\n",
    "и оптимизационная задача переписывается в виде:\n",
    "$$\\hat{\\theta} = \\arg \\min_{\\theta \\in \\mathbb{R}^n} \\sum_{i=1}^l\\bigr[f\\bigr(\\theta, \\mathbf{x}_i\\bigr) \\not= y_i\\bigr].$$\n",
    "\n",
    "Воспользуемся библиотеками для решения данной задачи. Далее в примере будет найден параметр $\\hat{\\theta}$ не как решение непосредственно этой оптимизационной задачи, а немного измененной, но об этом позже в следующей лекции."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Поиск оптимального вектора параметров\n",
    "Перейдем к двум матрицам:\n",
    "1. Матрице объектов $\\mathbf{X} \\in \\mathbb{R}^{l\\times (n+1)}$\n",
    "2. Вектору ответов $\\mathbf{y} \\in \\{-1,1\\}^l$\n",
    "\n",
    "Заметим, что объекты мы погрузили в пространство более большой размерности, добавив еще один признак, который у всех объектов будет равен $1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "X = binary_dataset.iloc[:, binary_dataset.columns != 'класс'].values\n",
    "y = binary_dataset.iloc[:, binary_dataset.columns == 'класс'].values.reshape(-1)\n",
    "X = np.array(np.hstack([X, np.ones([len(X), 1])]), dtype=np.float64)\n",
    "y = np.array(y, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=0, max_iter=2000)\n",
    "_ = model.fit(X, y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Получаем вектор оптимальных параметров $\\hat{\\theta}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Переход от бинарной классификации к многоклассовой\n",
    "Теперь же остается вопрос: как перейти от задачи бинарной классификации к многоклассовой? В качестве бинарного классификатора рассмотрим все ту же модель алгоритмов: \n",
    "$$\\mathfrak{F}_{bcl} = \\left\\{f\\bigr(\\theta, \\mathbf{x}\\bigr)=\\text{sign}\\bigr(\\theta^{\\mathsf{T}}\\mathbf{x}\\bigr)\\bigr| \\theta \\in \\mathbb{R}^{n} \\right\\}.$$\n",
    "\n",
    "Но знак позволяет отделить только два знака. Какие же есть решения?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Рассмотрим вариант перехода, который называется Один против всех (One VS All). Для простоты визуализации рассмотрим пример на синтетических данных. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Генерация синтетической выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "l = 100\n",
    "n = 2\n",
    "X1 = np.array([[-1,-1]]) + 0.5*np.random.randn(l, n)\n",
    "X2 = np.array([[1,1]]) + 0.5*np.random.randn(l, n)\n",
    "X3 = np.array([[-1,1]]) + 0.5*np.random.randn(l, n)\n",
    "\n",
    "X = np.vstack([X1, X2, X3])\n",
    "y = np.hstack([[0]*l, [1]*l, [2]*l])\n",
    "\n",
    "# Добавляем константу\n",
    "X = np.hstack([X, np.ones([len(X), 1])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "cols = ['blue', 'red', 'green']\n",
    "\n",
    "# построение точек\n",
    "for k in np.unique(y):\n",
    "    plt.plot(X[y==k,0], X[y==k,1], 'o', label='класс {}'.format(k), color=cols[k])\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Один против всех\n",
    "\n",
    "Данные метод основан на том, что для классификации на $M>2$ классов нужно построить $M$ линейных классификаторов, которые классифицируют $k$-й класс прорив всех остальных классов."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Построим $M=3$ классификатора, которые отделяют каждый класс от двух остальных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "model = LogisticRegression(random_state=0, max_iter=2000, fit_intercept=False)\n",
    "_ = model.fit(X, np.array(y==0, dtype=np.int64))\n",
    "models.append(model)\n",
    "\n",
    "model = LogisticRegression(random_state=0, max_iter=2000, fit_intercept=False)\n",
    "_ = model.fit(X, np.array(y==1, dtype=np.int64))\n",
    "models.append(model)\n",
    "\n",
    "model = LogisticRegression(random_state=0, max_iter=2000, fit_intercept=False)\n",
    "_ = model.fit(X, np.array(y==2, dtype=np.int64))\n",
    "models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def get_line(a, b, c=0, x_min=-10, x_max=10):\n",
    "    x1, y1 = -(-models[k].coef_[0][1] + c)/models[k].coef_[0][0], -1\n",
    "    x2, y2 = -(models[k].coef_[0][1] + c)/models[k].coef_[0][0], 1\n",
    "    \n",
    "    polynomial = np.poly1d(np.polyfit([x1, x2], [y1, y2], 1))\n",
    "    x_axis = np.linspace(x_min, x_max)\n",
    "    y_axis = polynomial(x_axis)\n",
    "    \n",
    "    return x_axis, y_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "cols = ['blue', 'red', 'green']\n",
    "plt.xlim((-2.5, 2.5))\n",
    "plt.ylim((-2.5, 2.5))\n",
    "\n",
    "for k in np.unique(y):\n",
    "    plt.plot(X[y==k,0], X[y==k,1], 'o', \n",
    "             label='класс {}'.format(k), color=cols[k])\n",
    "\n",
    "for k in np.unique(y):\n",
    "    plt.plot(*get_line(*models[k].coef_[0]), linewidth=2, color=cols[k])\n",
    "    print(models[k].coef_[0])\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Методы анализа качества\n",
    "\n",
    "Самый простой способо это подсчет ошибок, не верных классов:\n",
    "$$\\mathcal{L}\\bigr(\\theta, \\mathbf{X}, \\mathbf{y}\\bigr) = \\sum_{i=1}^l\\bigr[f\\bigr(\\theta, \\mathbf{x}_i\\bigr) \\not= y_i\\bigr].$$\n",
    "\n",
    "Также можно рассмотреть таблицу попарных ошибок:\n",
    "\n",
    "|               | y = 1 | y = 2 | y = 3 |\n",
    "| ------------- | ----- | ----- | ----- |\n",
    "| __f(x) = 1__  |  1-1  |  1-2  |  1-3  |\n",
    "| __f(x) = 2__  |  2-1  |  2-2  |  2-3  |\n",
    "| __f(x) = 3__  |  3-1  |  3-2  |  3-3  |\n",
    "\n",
    "Данная таблица показывает, сколько классификатор сделал ошибок между двумя парами классов. Например:\n",
    "1. 2-3 это число, которое обозначает, сколько объектов класса $3$ объект отнес к классу $2$\n",
    "2. 3-1 это число, которое обозначает, сколько объектов класса $1$ объект отнес к классу $3$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Посчитаем данную матрицу для синтетической выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "scores = np.zeros([3,3])\n",
    "for k in range(3):\n",
    "    pred = np.argmax(np.vstack([models[i].predict_proba(X[y==k])[:, 1] for i in range(3)]).T, axis=1)\n",
    "    for i in range(3):\n",
    "        scores[i, k] = sum(pred == i)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "print(scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Результаты данной таблицы показывают такой же результат как и картинка. Хуже всего от других отделим второй класс."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Servo dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numFolds = 10\n",
    "SEED = 888\n",
    "np.random.seed(SEED)\n",
    "\n",
    "colnames = [\"motor\", \"screw\", \"pgain\", \"vgain\", \"class\"]\n",
    "dataset = pd.read_csv(\"data/servo.data\", sep=\",\", names=colnames)\n",
    "\n",
    "# Some data preprocessing\n",
    "X = dataset.drop(\"class\", axis=1)\n",
    "Y = dataset[\"class\"]\n",
    "X_conv = pd.get_dummies(X, columns=colnames[:-1])\n",
    "print(X[0:3])\n",
    "print(X_conv[0:3])\n",
    "kf = KFold(numFolds, shuffle=True)\n",
    "\n",
    "Models = [LinearRegression, SVR]\n",
    "for Model in Models:\n",
    "    total = 0\n",
    "    for train_indices, test_indices in kf.split(X):\n",
    "        X_train = X_conv.iloc[train_indices, :]\n",
    "        Y_train = Y[train_indices]\n",
    "        \n",
    "        X_test = X_conv.iloc[test_indices, :]\n",
    "        Y_test = Y[test_indices]\n",
    "\n",
    "        # Testing out on the linear regression\n",
    "        reg = Model()\n",
    "        reg.fit(X_train, Y_train)\n",
    "\n",
    "        predictions = reg.predict(X_test)\n",
    "        mse = mean_squared_error(Y_test, predictions)\n",
    "        #mse = mean_absolute_error(Y_test, predictions)\n",
    "        total += mse\n",
    "    \n",
    "    mse = total / numFolds\n",
    "    print(\"Average mse of {0}: {1}\", Model.__name__, mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "tf25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "3e00b96764db5b0cdf5cee97e59d5a848d5550a9221e175d3badd9d15aef4d1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
